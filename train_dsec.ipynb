{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data\n",
    "import time\n",
    "from datasets import __datasets__\n",
    "from datasets.data_io import get_transform\n",
    "import gc\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from models.bgnet import BGNet\n",
    "from models.bgnet_plus import BGNet_Plus\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 11:46:07.356049: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 11:46:07.497574: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-11 11:46:08.166770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /disk2/users/M22_zhaoqinghao/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2024-01-11 11:46:08.166837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /disk2/users/M22_zhaoqinghao/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2024-01-11 11:46:08.166844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter \n",
    "writer = SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  model = 'bgnet_plus'\n",
    "  dataset = 'dsec_png'\n",
    "  datapath = '/home/zhaoqinghao/dataset/DSEC/output'\n",
    "  savepath = '/disk2/users/M22_zhaoqinghao/BGNet/output/'\n",
    "  trainlist = '/home/zhaoqinghao/DSEC/train.txt'\n",
    "  testlist = '/home/zhaoqinghao/DSEC/test.txt'\n",
    "  loadmodel = None\n",
    "  savemodel = './'\n",
    "  epochs = 233\n",
    "  no_cuda = False\n",
    "  seed = 1\n",
    "\n",
    "args = Args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 5315811\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "datapath = args.datapath\n",
    "StereoDataset = __datasets__[args.dataset]\n",
    "\n",
    "dsec_train = args.trainlist\n",
    "dsec_train_dataset = StereoDataset(datapath, dsec_train, True)\n",
    "TrainImgLoader = DataLoader(dsec_train_dataset, batch_size= 52, shuffle=True, num_workers=32, drop_last=False)\n",
    "\n",
    "dsec_test = args.testlist\n",
    "dsec_test_dataset = StereoDataset(datapath, dsec_test, False)\n",
    "TestImgLoader = DataLoader(dsec_test_dataset, batch_size= 8, shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "if args.model == 'bgnet':\n",
    "    model = BGNet().cuda()\n",
    "elif args.model == 'bgnet_plus':\n",
    "    model = BGNet_Plus().cuda()\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "if args.loadmodel is not None:\n",
    "    state_dict = torch.load(args.loadmodel, map_location=torch.device('cuda' if args.cuda else 'cpu'))\n",
    "    model.load_state_dict(state_dict.get('state_dict', {}), strict=False)\n",
    "    print('load model')\n",
    "    print(args.loadmodel)\n",
    "print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(imgL, imgR, disp_L):\n",
    "    model.train()\n",
    "    \n",
    "    if args.cuda:\n",
    "        imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_L.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output, _ = model(imgL, imgR)\n",
    "\n",
    "    disp_true = torch.squeeze(disp_true, 0)\n",
    "    disp_true = torch.squeeze(disp_true, 1)\n",
    "\n",
    "    mask = (disp_true > 0)\n",
    "    mask.detach_()\n",
    "    \n",
    "    loss = F.smooth_l1_loss(output[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(imgL,imgR,disp_true):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred,_ = model(imgL.cuda(), imgR.cuda())\n",
    "    disp_true = torch.squeeze(disp_true, 1)\n",
    "    pred_disp = pred.data.cpu()\n",
    "    mask = disp_true > 0\n",
    "    disp_diff = torch.abs(disp_true[mask] - pred_disp[mask])\n",
    "    err_mask = disp_diff > 3    # 3 pixel error\n",
    "    return torch.mean(err_mask.float())\n",
    "\n",
    "# def Thres_metric(D_est, D_gt, mask, thres):\n",
    "#     assert isinstance(thres, (int, float))\n",
    "#     D_est, D_gt = D_est[mask], D_gt[mask]\n",
    "#     E = torch.abs(D_gt - D_est)\n",
    "#     err_mask = E > thres\n",
    "#     return torch.mean(err_mask.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 3-px Accuracy in val = 1.656\n",
      "Iter 1 3-px Accuracy in val = 1.346\n",
      "Iter 2 3-px Accuracy in val = 1.629\n",
      "Iter 3 3-px Accuracy in val = 1.816\n",
      "Iter 4 3-px Accuracy in val = 1.296\n",
      "Iter 5 3-px Accuracy in val = 1.701\n",
      "Iter 6 3-px Accuracy in val = 1.858\n",
      "Iter 7 3-px Accuracy in val = 1.422\n",
      "Iter 8 3-px Accuracy in val = 1.152\n",
      "Iter 9 3-px Accuracy in val = 1.589\n",
      "Iter 10 3-px Accuracy in val = 2.173\n",
      "Iter 11 3-px Accuracy in val = 2.388\n",
      "Iter 12 3-px Accuracy in val = 2.038\n",
      "Iter 13 3-px Accuracy in val = 2.241\n",
      "Iter 14 3-px Accuracy in val = 2.028\n",
      "Iter 15 3-px Accuracy in val = 1.125\n",
      "Iter 16 3-px Accuracy in val = 1.488\n",
      "Iter 17 3-px Accuracy in val = 1.477\n",
      "Iter 18 3-px Accuracy in val = 1.884\n",
      "Iter 19 3-px Accuracy in val = 1.868\n",
      "Iter 20 3-px Accuracy in val = 1.292\n",
      "Iter 21 3-px Accuracy in val = 1.606\n",
      "Iter 22 3-px Accuracy in val = 2.010\n",
      "Iter 23 3-px Accuracy in val = 1.717\n",
      "Iter 24 3-px Accuracy in val = 1.272\n",
      "Iter 25 3-px Accuracy in val = 1.440\n",
      "Iter 26 3-px Accuracy in val = 1.028\n",
      "Iter 27 3-px Accuracy in val = 1.693\n",
      "Iter 28 3-px Accuracy in val = 2.345\n",
      "Iter 29 3-px Accuracy in val = 2.557\n",
      "Iter 30 3-px Accuracy in val = 1.182\n",
      "Iter 31 3-px Accuracy in val = 1.367\n",
      "Iter 32 3-px Accuracy in val = 2.006\n"
     ]
    }
   ],
   "source": [
    "total_test_loss = 0\n",
    "for batch_idx, sample in enumerate(TestImgLoader):\n",
    "    imgL, imgR, disp_L = sample['left'], sample['right'], sample['disparity']\n",
    "    test_loss = test(imgL, imgR, disp_L)\n",
    "    writer.add_scalar('Test Loss', test_loss, batch_idx)\n",
    "    print('Iter %d 3-px Accuracy in val = %.3f' %(batch_idx, test_loss*100))\n",
    "    total_test_loss += test_loss\n",
    "\n",
    "# print('epoch %d total 3-px Accuracy in val = %.3f' %(epoch, total_test_loss/len(TestImgLoader)*100))\n",
    "\n",
    "# if total_test_loss/len(TestImgLoader)*100 > max_acc:\n",
    "#     max_acc = total_test_loss/len(TestImgLoader)*100\n",
    "#     max_epo = epoch\n",
    "\n",
    "# print('MAX epoch %d total test Accuracy = %.3f' %(max_epo, max_acc))\n",
    "\n",
    "# print('full finetune time = %.2f HR' %((time.time() - start_full_time)/3600))\n",
    "# print(max_epo)\n",
    "# print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch <= 200:\n",
    "       lr = 0.001\n",
    "    else:\n",
    "       lr = 0.0001\n",
    "    print('learning rate = %.6f' %(lr))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = 0\n",
    "max_epo = 0\n",
    "start_full_time = time.time()\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    print('This is %d-th epoch' %(epoch))\n",
    "    total_train_loss = 0\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('epoch %d' %(epoch))\n",
    "    for batch_idx, sample in enumerate(TrainImgLoader):\n",
    "        start_time = time.time()\n",
    "        imgL, imgR, disp_L = sample['left'], sample['right'], sample['disparity']\n",
    "        loss = train(imgL.cuda(), imgR.cuda(), disp_L.cuda())\n",
    "        \n",
    "        # Record batch_idx and loss to TensorBoard\n",
    "        writer.add_scalar('Train Loss', loss, epoch * len(TrainImgLoader)+batch_idx)\n",
    "        \n",
    "        # print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
    "        total_train_loss += loss\n",
    "    print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
    "    \n",
    "    # Record epoch and total_train_loss to TensorBoard\n",
    "    writer.add_scalar('Total Train Loss', total_train_loss/len(TrainImgLoader), epoch)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        savefilename = args.savemodel+'checkpoint_'+str(epoch)+'.pth'\n",
    "        torch.save(model.state_dict(), savefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "max_acc = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
