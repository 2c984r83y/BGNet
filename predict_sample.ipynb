{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from datasets import __datasets__\n",
    "import gc\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datasets.data_io import get_transform\n",
    "from models.bgnet import BGNet\n",
    "from models.bgnet_plus import BGNet_Plus\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BGNet_Plus().cuda()\n",
    "checkpoint = torch.load('./pretrained_models/checkpoint_230.pth',map_location=lambda storage, loc: storage)\n",
    "# checkpoint = torch.load('./pretrained_models/Sceneflow-IRS-BGNet-Plus.pth',map_location=lambda storage, loc: storage)\n",
    "# checkpoint = torch.load('./pretrained_models/finetune_30_dsec.pth',map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint) \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img = Image.open('/home/zhaoqinghao/DSEC/output/left/000167.png').convert('L')\n",
    "right_img = Image.open('/home/zhaoqinghao/DSEC/output/right/000167.png').convert('L')\n",
    "disp_true = Image.open('/home/zhaoqinghao/DSEC/output/disp/000167.png').convert('L')\n",
    "left_img = left_img.crop((0, 0, 640, 448))\n",
    "right_img = right_img.crop((0, 0, 640, 448))\n",
    "disp_true = disp_true.crop((0, 0, 640, 448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_img = Image.open('/home/zhaoqinghao/dataset/KITTI_2015/training/image_2/000001_10.png').convert('L')\n",
    "# right_img = Image.open('/home/zhaoqinghao/dataset/KITTI_2015/training/image_3/000001_10.png').convert('L')\n",
    "# disp_true = Image.open('/home/zhaoqinghao/dataset/KITTI_2015/training/disp_occ_0/000001_10.png').convert('L')\n",
    "# left_img = left_img.crop((0, 0, 1216, 320))\n",
    "# right_img = right_img.crop((0, 0, 1216, 320))\n",
    "# disp_true = disp_true.crop((0, 0, 1216, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img = np.ascontiguousarray(left_img, dtype=np.float32)\n",
    "right_img = np.ascontiguousarray(right_img, dtype=np.float32)\n",
    "disp_true = np.ascontiguousarray(disp_true, dtype=np.float32)\n",
    "\n",
    "preprocess = get_transform()    # get_transform()函数返回一个转换列表，它将图像转换为 PyTorch 张量\n",
    "left_img = preprocess(left_img)\n",
    "right_img = preprocess(right_img)\n",
    "disp_true = preprocess(disp_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred,_ = model(left_img.unsqueeze(0).cuda(), right_img.unsqueeze(0).cuda())\n",
    "    pred,_ = model(left_img.unsqueeze(0).cuda(), right_img.unsqueeze(0).cuda())\n",
    "time_start=time.time()\n",
    "with torch.no_grad():\n",
    "    pred,_ = model(left_img.unsqueeze(0).cuda(), right_img.unsqueeze(0).cuda())\n",
    "# print time cost\n",
    "print('time cost: ',(time.time()-time_start)*1000,'ms')\n",
    "print('FPS: ',1/(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_true = torch.squeeze(disp_true, 1)\n",
    "disp_pred = pred.data.cpu()\n",
    "mask = disp_true > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D1_metric(D_est, D_gt, mask):\n",
    "    D_est, D_gt = D_est[mask], D_gt[mask]\n",
    "    E = torch.abs(D_gt - D_est)\n",
    "    err_mask = (E > 3) & (E / D_gt.abs() > 0.05)\n",
    "    return torch.mean(err_mask.float())\n",
    "\n",
    "def Thres_metric(D_est, D_gt, mask, thres):\n",
    "    assert isinstance(thres, (int, float))\n",
    "    D_est, D_gt = D_est[mask], D_gt[mask]\n",
    "    E = torch.abs(D_gt - D_est)\n",
    "    err_mask = E > thres\n",
    "    return torch.mean(err_mask.float())\n",
    "\n",
    "# NOTE: please do not use this to build up training loss\n",
    "def EPE_metric(D_est, D_gt, mask):\n",
    "    D_est, D_gt = D_est[mask], D_gt[mask]\n",
    "    return F.l1_loss(D_est, D_gt, size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End Point Error (EPE)\n",
    "print('EPE: ', EPE_metric(disp_pred, disp_true, mask).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors larger than 1 pixels (1 pixel error / bad 1.0)\n",
    "print('1-px err: ', Thres_metric(disp_pred, disp_true, mask, 1).item() * 100, '%')\n",
    "print('2-px err: ', Thres_metric(disp_pred, disp_true, mask, 2).item() * 100, '%')\n",
    "print('3-px err: ', Thres_metric(disp_pred, disp_true, mask, 3).item() * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of disparity outliers D1, errors greater than max(3px, 0.05d∗)\n",
    "print('D1: ',D1_metric(disp_pred, disp_true, mask).item() * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save disp\n",
    "pred = pred[0].data.cpu().numpy() * 256\n",
    "skimage.io.imsave('sample_disp.png',pred.astype('uint16'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
